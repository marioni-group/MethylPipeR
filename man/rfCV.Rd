% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rf.R
\name{rfCV}
\alias{rfCV}
\title{rfCV}
\usage{
rfCV(
  dataset,
  labels,
  foldIDs,
  metric = "AUC",
  ntrees,
  mtrys,
  nodesizes,
  pipelineRunInformation,
  testXs = NULL,
  testY = NULL
)
}
\arguments{
\item{dataset}{A matrix/data.frame corresponding to X (variables) to be used in the cross-validation.}

\item{labels}{A vector/list corresponding to Y (labels) to be used in the cross-validation.}

\item{foldIDs}{A vector/list with the same length as labels denoting for each row in the dataset, which fold it will be assigned to.}

\item{metric}{'AUC' or 'PRAUC', the metric that will be used to determine the optimal hyperparameters in the grid search.}

\item{ntrees}{A vector/list containing all the values of ntree to be tried in the grid search.}

\item{mtrys}{A vector/list containing all the values of mtry to be tried in the grid search.}

\item{nodesizes}{A vector/list containing all the values of nodesize to be tried in the grid search.}

\item{pipelineRunInformation}{The object originally created by beginPipelineRun.}

\item{testXs}{A matrix/data.frame corresponding to the test set X (variables) used to evaluate the final model. If NULL, the training set is used as the test set.}

\item{testY}{A vector/list corresponding to the test set Y (labels) to be used to evaluate the final model. If NULL, the training set labels are used.}
}
\value{
A data.frame showing for each combination of hyperparameters, the (mean) metric calculated on the test fold predictions.
}
\description{
rfCV
}
